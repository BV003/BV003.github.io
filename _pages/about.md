---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a tenure-track Assistant Professor in the Department of Computer Science at the University of Virginia (UVA). Before joining UVA in 2024, I earned my Ph.D. from the University of Illinois Urbana-Champaign (UIUC), where I was advised by [Jiawei Han](http://hanj.cs.illinois.edu/). During my Ph.D., I also spent time as a visiting researcher with the Princeton NLP Group, working with [Danqi Chen](https://www.cs.princeton.edu/~danqic/).

<div class="announcement">
<p><strong>I am looking for self-motivated PhD students and interns!</strong> Please fill out <a href="https://forms.gle/ZsEyYewLogXodujc7">this form</a> if you are interested in working with me. After completing the form, you are also welcome to reach out via email. I will read all submitted forms and emails but I do apologize for not being able to respond to each of them!</p>
</div>

<h2 class="pub-subhead" style="border-left:none; padding-left:0; font-size:1.9em;">Research</h2>
<p>My research is dedicated to developing more <strong>capable, efficient, and aligned</strong> Large Language Models (LLMs). I work across the entire LLM lifecycle, including training paradigms, data and inference efficiency, and the foundations of representations.</p>

<h3 class="pub-subhead">Post-Training: Aligning and Enhancing LLMs</h3>
<p class="section-desc">My recent work designs better post-training algorithms to improve reasoning, factuality, preference alignment, and model-based evaluation.</p>
<ul class="pub-list">
  <li class="pub-item"><span class="badge">arXiv 2025</span> <a href="https://zhuxinyu.top/">Zhu</a> <em>et al.</em> <strong><a href="https://arxiv.org/abs/2506.01347">The Surprising Effectiveness of Negative Reinforcement in LLM Reasoning</a></strong></li>
  <li class="pub-item"><span class="badge">arXiv 2025</span> <a href="https://wlchen0206.github.io/">Chen</a> <em>et al.</em> <strong><a href="https://arxiv.org/abs/2504.03846">Do LLM Evaluators Prefer Themselves for a Reason?</a></strong></li>
  <li class="pub-item"><span class="badge">ICLR 2025</span> <a href="https://weizhepei.com/">Wei</a> <em>et al.</em> <strong><a href="https://arxiv.org/abs/2406.13629">InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales</a></strong></li>
  <li class="pub-item"><span class="badge">NeurIPS 2024</span> Meng <em>et al.</em> <strong><a href="https://arxiv.org/abs/2405.14734">SimPO: Simple Preference Optimization with a Reference-Free Reward</a></strong></li>
</ul>

<h3 class="pub-subhead">Efficiency: Overcoming Data and Inference Bottlenecks</h3>
<p class="section-desc">My research addresses critical bottlenecks in data efficiency and inference efficiency, from synthetic data generation to faster decoding.</p>
<ul class="pub-list">
  <li class="pub-item"><span class="badge">ICML 2025</span> <a href="https://weizhepei.com/">Wei</a> <em>et al.</em> <strong><a href="https://arxiv.org/abs/2506.03700">AdaDecode: Accelerating LLM Decoding with Adaptive Layer Parallelism</a></strong></li>
  <li class="pub-item"><span class="badge">ICML 2023</span> Meng <em>et al.</em> <strong><a href="https://arxiv.org/abs/2211.03044">Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning</a></strong></li>
  <li class="pub-item"><span class="badge">NeurIPS 2022</span> Meng <em>et al.</em> <strong><a href="https://arxiv.org/abs/2202.04538">Generating Training Data with Language Models: Towards Zero-Shot Language Understanding</a></strong></li>
</ul>

<h3 class="pub-subhead">Foundations of Representation Learning</h3>
<p class="section-desc">My work investigates the core principles of representation learning, uncovers limitations in language model representations, and proposes novel pre-training objectives to build more robust and capable foundation models.</p>
<ul class="pub-list">
  <li class="pub-item"><span class="badge">ICLR 2024</span> Meng <em>et al.</em> <strong><a href="https://arxiv.org/abs/2302.02060">Representation Deficiency in Masked Language Modeling</a></strong></li>
  <li class="pub-item"><span class="badge">ICLR 2022</span> Meng <em>et al.</em> <strong><a href="https://arxiv.org/abs/2204.03243">Pretraining Text Encoders with Adversarial Mixture of Training Signal Generators</a></strong></li>
  <li class="pub-item"><span class="badge">NeurIPS 2021</span> Meng <em>et al.</em> <strong><a href="https://arxiv.org/abs/2102.08473">COCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining</a></strong></li>
</ul>

<h2 class="pub-subhead" style="border-left:none; padding-left:0; font-size:1.9em;">News</h2>
<ul class="news-list">
  <li class="news-item"><span class="news-date">2025 Service</span><span class="news-content">Area Chair: <strong>ICLR, ICML, COLM, NeurIPS</strong>. Action Editor: <strong>TMLR</strong>.</span></li>
  <li class="news-item"><span class="news-date">2025.05</span><span class="news-content">Two papers on Accelerating LLM Decoding (<a href="https://arxiv.org/abs/2506.03700">AdaDecode</a>) and Retrieval-Inspired Preference Alignment (<a href="https://arxiv.org/abs/2502.03699">LarPO</a>) accepted to <strong>ICML 2025</strong>!</span></li>
  <li class="news-item"><span class="news-date">2025.04</span><span class="news-content">Honored to be named to the <a href="https://www.forbes.com/30-under-30/2025/asia/healthcare-science">Forbes 30 Under 30 2025 Asia list (Healthcare & Science)</a>!</span></li>
  <li class="news-item"><span class="news-date">2025.01</span><span class="news-content">One paper on Retrieval-Augmented Generation (<a href="https://arxiv.org/abs/2406.13629">InstructRAG</a>) accepted to <strong>ICLR 2025</strong>!</span></li>
  <li class="news-item"><span class="news-date">2024.09</span><span class="news-content">Two papers on Preference Optimization (<a href="https://arxiv.org/abs/2405.14734">SimPO</a>) and Contrastive Decoding in MoE (<a href="https://arxiv.org/abs/2405.14507">SCMoE</a>) accepted to <strong>NeurIPS 2024</strong>!</span></li>
  <li class="news-item"><span class="news-date">2024.09</span><span class="news-content">Two papers on <a href="https://arxiv.org/abs/2402.11142">Zero-Shot Relation Extraction</a> and <a href="https://arxiv.org/abs/2406.01171">LLM Persona Survey</a> accepted to <strong>EMNLP 2024</strong> Main Conference/Findings!</span></li>
  <li class="news-item"><span class="news-date">2024.08</span><span class="news-content">My Ph.D. thesis won the <a href="https://kdd2024.kdd.org/awards/">ACM SIGKDD 2024 Dissertation Award</a>!</span></li>
</ul>

<h2 class="pub-subhead" style="border-left:none; padding-left:0; font-size:1.9em;">Education</h2>
<dl class="edu-list">
  <dt>Ph.D. (2023) Computer Science, University of Illinois Urbana-Champaign</dt>
  <dd><strong>Thesis:</strong> <a href="https://www.ideals.illinois.edu/items/129146">Efficient and Effective Learning of Text Representations</a> <span class="badge-accent badge">Award</span> <a href="https://kdd2024.kdd.org/awards/">ACM SIGKDD 2024 Dissertation Award</a></dd>
  <dt>M.S. (2019) Computer Science, University of Illinois Urbana-Champaign</dt>
  <dd><strong>Thesis:</strong> <a href="https://www.ideals.illinois.edu/items/111979">Weakly-Supervised Text Classification</a></dd>
  <dt>B.S. (2017) Computer Engineering, University of Illinois Urbana-Champaign</dt>
  <dd>Graduated with Highest Honor & <a href="https://digital.library.illinois.edu/items/592ebe50-1be8-0136-4cfa-0050569601ca-5#?c=0&m=0&s=0&cv=0&r=0&xywh=-3461%2C0%2C12837%2C5932">Bronze Tablet</a></dd>
</dl>

<h2 class="pub-subhead" style="border-left:none; padding-left:0; font-size:1.9em;">Contact</h2>
<ul class="pub-list">
  <li class="pub-item"><strong>Email:</strong> yumeng5[at]virginia[dot]edu</li>
  <li class="pub-item"><strong>Office:</strong> Rice Hall 408, 85 Engineer's Way, Charlottesville, Virginia 22903</li>
</ul>