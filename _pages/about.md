---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Research Assistant.

> **Announcement:** I am always open to collaboration. Feel free to drop me an e-mail!

## Research


My research is dedicated to developing more **capable, efficient, and aligned** Large Language Models (LLMs). I work across the entire LLM lifecycle, including training paradigms, data and inference efficiency, and the foundations of representations.

### Post-Training: Aligning and Enhancing LLMs
My recent work designs better post-training algorithms to improve reasoning, factuality, preference alignment, and model-based evaluation.

### Efficiency: Overcoming Data and Inference Bottlenecks
My research addresses critical bottlenecks in data efficiency and inference efficiency, from synthetic data generation to faster decoding.



## News


- **2025.05** — Two papers !

## Education


- **B.S. (2022)** — Software Engineering — WuHan University  

## Contact


- **Email:**  
